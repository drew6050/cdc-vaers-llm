{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Fine-Tuned LLM DistilBERT to Classify User VARES Adverse Event Symptoms Text Descriptions \n",
    "#### To predict more than just the first symptom (SYMPTOM1), a different approach is needed to handle multiple label prediction. This is typically done using a multi-label classification setup, where each symptom is treated as a separate label, and the model learns to predict the presence or absence of each symptom independently (using a MultiLabelBinarizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin c:\\Users\\User\\text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cpu.so\n",
      "function 'cadam32bit_grad_fp32' not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\text-generation-webui-main\\installer_files\\env\\Lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Load and preprocess the VAERS data and symptoms\n",
    "vaers_data_path = 'data/2023VAERSDATA.csv'\n",
    "vaers_symptoms_path = 'data/2023VAERSSYMPTOMS.csv'\n",
    "vaers_data = pd.read_csv(vaers_data_path, encoding='ISO-8859-1')\n",
    "vaers_symptoms = pd.read_csv(vaers_symptoms_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Merge datasets on VAERS_ID\n",
    "merged_data = vaers_data.merge(vaers_symptoms, on='VAERS_ID')\n",
    "merged_data['SYMPTOM_TEXT'] = merged_data['SYMPTOM_TEXT'].astype(str)\n",
    "\n",
    "# Concatenate symptoms into a single string for each row\n",
    "merged_data['ALL_SYMPTOMS'] = merged_data[['SYMPTOM1', 'SYMPTOM2', 'SYMPTOM3', 'SYMPTOM4', 'SYMPTOM5']].apply(lambda x: ', '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "# Group by VAERS_ID and aggregate data\n",
    "grouped = merged_data.groupby('VAERS_ID').agg({\n",
    "    # Include all necessary columns here\n",
    "    'SYMPTOM_TEXT': 'first',\n",
    "    'ALL_SYMPTOMS': ' '.join\n",
    "}).reset_index()\n",
    "\n",
    "# Split the 'ALL_SYMPTOMS' into a list of symptoms\n",
    "grouped['ALL_SYMPTOMS'] = grouped['ALL_SYMPTOMS'].str.split(', ')\n",
    "\n",
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Transform the symptoms into a multi-label format with 'Encoded_Symptoms' column contains a binary matrix for multi-label classification\n",
    "grouped['Encoded_Symptoms'] = list(mlb.fit_transform(grouped['ALL_SYMPTOMS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAERS_ID</th>\n",
       "      <th>SYMPTOM_TEXT</th>\n",
       "      <th>ALL_SYMPTOMS</th>\n",
       "      <th>Encoded_Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2547730</td>\n",
       "      <td>The adverse event is that the patient went int...</td>\n",
       "      <td>[Blood pressure orthostatic abnormal, COVID-19...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2547731</td>\n",
       "      <td>Error: Incorrect Reconstitution-</td>\n",
       "      <td>[Product preparation issue]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2547732</td>\n",
       "      <td>Error: Patient Accidentally Stuck by Needle-</td>\n",
       "      <td>[Injury associated with device]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2547733</td>\n",
       "      <td>Error: Dose in Series Given Too Early-</td>\n",
       "      <td>[Inappropriate schedule of product administrat...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2547734</td>\n",
       "      <td>Systemic: EYE TWITCHING-Medium</td>\n",
       "      <td>[Blepharospasm]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>2552744</td>\n",
       "      <td>Immediately following injection my heart rate ...</td>\n",
       "      <td>[Angina pectoris, Asthenia, Chest pain, Condit...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>2552745</td>\n",
       "      <td>Got sinus infection went to urgent care prescr...</td>\n",
       "      <td>[Influenza virus test positive, Sinusitis]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>2552746</td>\n",
       "      <td>Vaccine was no diluted prior to vaccination.</td>\n",
       "      <td>[Product preparation error]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>2552747</td>\n",
       "      <td>Vaccine was not diluted prior to vaccination.</td>\n",
       "      <td>[Product preparation error]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>2552748</td>\n",
       "      <td>Congestive heart Failure/ Stroke</td>\n",
       "      <td>[Cardiac failure congestive, Cerebrovascular a...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VAERS_ID                                       SYMPTOM_TEXT  \\\n",
       "0      2547730  The adverse event is that the patient went int...   \n",
       "1      2547731                   Error: Incorrect Reconstitution-   \n",
       "2      2547732       Error: Patient Accidentally Stuck by Needle-   \n",
       "3      2547733             Error: Dose in Series Given Too Early-   \n",
       "4      2547734                     Systemic: EYE TWITCHING-Medium   \n",
       "...        ...                                                ...   \n",
       "2995   2552744  Immediately following injection my heart rate ...   \n",
       "2996   2552745  Got sinus infection went to urgent care prescr...   \n",
       "2997   2552746       Vaccine was no diluted prior to vaccination.   \n",
       "2998   2552747      Vaccine was not diluted prior to vaccination.   \n",
       "2999   2552748                   Congestive heart Failure/ Stroke   \n",
       "\n",
       "                                           ALL_SYMPTOMS  \\\n",
       "0     [Blood pressure orthostatic abnormal, COVID-19...   \n",
       "1                           [Product preparation issue]   \n",
       "2                       [Injury associated with device]   \n",
       "3     [Inappropriate schedule of product administrat...   \n",
       "4                                       [Blepharospasm]   \n",
       "...                                                 ...   \n",
       "2995  [Angina pectoris, Asthenia, Chest pain, Condit...   \n",
       "2996         [Influenza virus test positive, Sinusitis]   \n",
       "2997                        [Product preparation error]   \n",
       "2998                        [Product preparation error]   \n",
       "2999  [Cardiac failure congestive, Cerebrovascular a...   \n",
       "\n",
       "                                       Encoded_Symptoms  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2996  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = grouped[0:2000]\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data with labels into test and train\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    grouped['SYMPTOM_TEXT'].tolist(), \n",
    "    grouped['Encoded_Symptoms'].tolist(), \n",
    "    test_size=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for pytorch\n",
    "\n",
    "class VAERSSymptomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])  # Correctly return the length of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=23829, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data and load the Pretrained DistilBERT Model for Multi-Label Classification\n",
    "\n",
    "train_dataset = VAERSSymptomDataset(train_encodings, train_labels)\n",
    "val_dataset = VAERSSymptomDataset(val_encodings, val_labels)\n",
    "\n",
    "# Number of unique labels (symptoms) to classify\n",
    "num_labels = len(mlb.classes_)\n",
    "\n",
    "# Load Pretrained DistilBERT Model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 79/507 [1:23:40<7:58:48, 67.12s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',            \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "\n",
    "# Start fine-tuning\n",
    "trainer.train()\n",
    "\n",
    "# 1000 in 2.5 hours, predicts the same lables for all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average='micro')\n",
    "    recall = recall_score(labels, preds, average='micro')\n",
    "    f1 = f1_score(labels, preds, average='micro')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine-tuned model\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions, labels, _ = trainer.predict(val_dataset)\n",
    "# Convert predictions to binary format (0 or 1)\n",
    "threshold = 0.5  # You might need to adjust this threshold\n",
    "predicted_labels = (predictions > threshold).astype(int)\n",
    "\n",
    "# Inverse transform to get symptom names from binary labels\n",
    "predicted_symptoms = mlb.inverse_transform(predicted_labels)\n",
    "actual_symptoms = mlb.inverse_transform(labels)\n",
    "\n",
    "# Creating the DataFrame\n",
    "val_texts_series = pd.Series(val_texts, name='SYMPTOM_TEXT')\n",
    "df_results = pd.DataFrame({\n",
    "    'VAERS_ID': merged_data.loc[val_texts_series.index, 'VAERS_ID'],\n",
    "    'SYMPTOM_TEXT': val_texts_series.values,\n",
    "    'ActualSymptoms': ['; '.join(symptoms) for symptoms in actual_symptoms],\n",
    "    'PredictedSymptoms': ['; '.join(symptoms) for symptoms in predicted_symptoms]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation metrics\n",
    "metrics = compute_metrics(predicted_labels, labels)\n",
    "\n",
    "print(metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
